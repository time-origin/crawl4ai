# 项目打包与执行指南

本文档提供两种部署和执行本项目的方式：使用 Docker（推荐）和打包为原生可执行文件。

---

## 一、使用 Docker 打包与执行 (推荐)

此方式通过 Docker 容器进行部署，环境隔离性好，是生产环境的首选方案。

### 1. 打包项目 (构建镜像)

在项目根目录 (`crawl4ai`) 下打开终端，并执行以下命令来构建镜像：

```sh
docker build -t custom-crawl4ai -f Dockerfile-custom .
```

### 2. 执行爬虫

构建好镜像后，你可以使用 `docker run` 命令来启动一个容器并执行爬虫任务。

**示例 1: 基本执行**
```sh
docker run --rm -it custom-crawl4ai python -m crawl4ai.crawlers.x_com.production_crawler --keyword "OpenAI"
```

**示例 2: 带全参数执行**
```sh
docker run --rm -it custom-crawl4ai python -m crawl4ai.crawlers.x_com.production_crawler \
    --keyword "generative AI" \
    --scan-scrolls 3 \
    --max-replies 10 \
    --reply-scrolls 8 \
    --output-method kafka \
    --kafka-key-prefix "x.com"
```

---

## 二、打包为完全独立的可执行文件 (高级)

此方法可以将项目（包括 Python 解释器、所有依赖库和 Playwright 浏览器）打包成一个**单文件可执行程序**。这使得程序可以**在任何未安装 Python 或浏览器的目标机器上直接运行**，真正实现“开箱即用”。

### 第1步：环境准备 (打包机器)

#### 步骤 1.1: 创建并激活虚拟环境 (强烈推荐)

在项目根目录 (`crawl4ai`) 下执行以下命令：

```sh
# 1. 创建虚拟环境
python -m venv venv

# 2. 激活虚拟环境
#    - Windows: venv\Scripts\activate
#    - Linux/macOS: source venv/bin/activate
source venv/bin/activate
```

#### 步骤 1.2: 安装依赖和工具

在已激活的虚拟环境中执行：

```sh
# 从 requirements.txt 文件安装所有依赖
pip install -r requirements.txt

# 下载 Playwright 所需的浏览器
playwright install
```

### 第2步：执行打包命令 (最终版)

在项目根目录 (`crawl4ai`) 下，根据你的目标操作系统执行以下命令。此命令整合了所有已知问题的解决方案。

#### Linux / macOS 打包命令 (最终推荐):

```shell
pyinstaller --onefile --name production_crawler_linux --paths . \
--collect-all playwright \
--hidden-import "crawl4ai.crawlers.x_com.scenes.search_scene" \
--hidden-import "crawl4ai.crawlers.x_com.scenes.tweet_detail_scene" \
--add-data "$(python -c 'import os, fake_http_header; print(os.path.dirname(fake_http_header.__file__))')/data:fake_http_header/data" \
--add-data "$(python -c 'import os, playwright_stealth; print(os.path.dirname(playwright_stealth.__file__))')/js:playwright_stealth/js" \
--add-data "$(python -c 'from playwright.sync_api import sync_playwright; from pathlib import Path; p=sync_playwright().start(); print(Path(p.chromium.executable_path).parent.parent.parent); p.stop()'):ms-playwright" \
crawl4ai/crawlers/x_com/production_crawler.py
```

打包完成后，最终的可执行文件会存放在项目根目录的 `dist` 文件夹下。

### 第3步：部署和执行

#### 步骤 3.1: 在目标服务器安装浏览器依赖 (仅需一次)

**这是解决在无图形界面的服务器上浏览器无法启动 (`TargetClosedError`) 的关键步骤。**

在**目标 Linux 服务器**上以 root 权限执行以下命令，它会自动安装 Chromium 运行所需的所有系统库。

```sh
sudo playwright install-deps
```

#### 步骤 3.2: 部署文件

1.  将 `dist` 文件夹下生成的可执行文件（例如 `production_crawler_linux`）复制到任何目标 Linux 机器上。
2.  在该可执行文件旁边创建一个 `.env` 文件，用于配置程序（如 Kafka 地址、代理、AUTH_JSON_PATH 等）。

#### 步骤 3.3: 运行程序

在目标机器上打开终端，进入可执行文件所在的目录，然后像普通程序一样运行它。

首先，给文件添加执行权限：
```shell
chmod +x ./production_crawler_linux
```

然后执行：
```shell
./production_crawler_linux --keyword "generative AI" --scan-scrolls 3
```

---

## 三、高级技巧与问题排查

### 1. 清理旧的打包文件

在重新打包之前，删除 `dist` 和 `build` 文件夹以及 `.spec` 文件可以确保一个完全干净的构建环境，避免旧文件的干扰。

```sh
rm -rf dist/ build/ *.spec
```

### 2. 增强反检测能力

如果担心被网站检测，可以在 `production_crawler.py` 的 `MockBrowserManager` 中为 `stealth_async` 添加更多伪装选项。

```python
# 位于 MockBrowserManager.new_page 方法中
await stealth_async(page, extra_options={
    'mask_linux': True,      # 隐藏 Linux 系统特征
    'hide_playwright': True, # 隐藏 Playwright 特征
    'fake_os': 'win32'         # 将平台伪装成 Windows
})
```

### 3. 创建环境诊断参数

为了方便在目标机器上排查问题，可以为 `production_crawler.py` 增加一个 `--check-env` 参数，当执行时，它会打印出所有关键路径和配置信息，然后立即退出。

**在 `argparse` 部分添加:**
```python
parser.add_argument("--check-env", action="store_true", help="Diagnose runtime environment and exit.")
```

**在 `main` 函数顶部添加:**
```python
if args.check_env:
    print("=== Environment Check ===")
    print(f"Running in bundled mode: {getattr(sys, 'frozen', False)}")
    print(f"Playwright browsers path: {os.environ.get('PLAYWRIGHT_BROWSERS_PATH')}")
    print(f"Auth file path: {AUTH_STATE_PATH}")
    print(f"Auth file exists: {AUTH_STATE_PATH.exists()}")
    # ...可以打印更多你关心的配置...
    return
```
